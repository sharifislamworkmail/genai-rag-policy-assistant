ğŸ§  GenAI RAG Policy Assistant
Retrieval-Augmented Generation (RAG) Based Policy Search Engine

ğŸ“Œ Project Overview

This project implements a Retrieval-Augmented Generation (RAG) system that enables users to query company policy documents using natural language.

Instead of relying only on a Large Language Model (LLM), this system:

    1. Converts policy documents into embeddings
    2. Stores them in a local vector database (ChromaDB)
    3. Retrieves relevant content for a query
    4. Uses GPT-4o-mini to generate grounded responses
    5. Provides citations for transparency

The result is a secure, explainable policy search assistant.

ğŸ—ï¸ System Architecture

User Question
      â†“
Streamlit UI
      â†“
Query Embedding (OpenAI)
      â†“
ChromaDB (Local Vector Store)
      â†“
Top-K Relevant Chunks Retrieved
      â†“
Prompt Construction
      â†“
GPT-4o-mini (Answer Generation)
      â†“
Final Answer with Citations

---
ğŸ“‚ Project Structure

genai-rag-policy-assistant/
â”‚
â”œâ”€â”€ Final_Project_RAG_SearchEngine.ipynb     # Main notebook (step-by-step RAG pipeline)
â”œâ”€â”€ app.py                                   # Streamlit application
â”œâ”€â”€ requirements.txt                         # Project dependencies
â”œâ”€â”€ README.md                                # Project documentation
â”œâ”€â”€ .env.example                             # Sample environment file
â”œâ”€â”€ Policy documents/                        # Policy PDFs
â”‚     â””â”€â”€ XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf
â””â”€â”€ Project_Report.docx                      # Detailed academic report

---
âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
    1. Clone the repository: git clone <your-repo-link>
    2. Navigate to project folder:  cd "D:\Gen_AI\Final Project"

2ï¸âƒ£ Install Dependencies:  pip install -r requirements.txt

3ï¸âƒ£ Create Environment File: Create a .env file in the project root:  OPENAI_API_KEY=your_openai_api_key

---
â–¶ï¸ Running the Project
## Option A â€” Notebook Version (Step-by-Step Execution)

1. Place your policy PDF (XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf) inside: /Policy documents/
2. Ensure .env file contains your API key
3. Activate your Python environment
4. Launch Jupyter:  python -m jupyter notebook
5. Open: Final_Project_Sharif_Islam_RAG_SearchEngine.ipynb
6. Run all cells sequentially
7. Ask questions in the interactive prompt cell

Expected Output:
1. Generated answer
2. Source citations (document + page number)

## Option B â€” Streamlit Application (Recommended for Demo)
1. Ensure:
    * app.py exists
    *  Policy PDFs are in /Policy documents/
    *  .env file contains API key
    *   Dependencies are installed

2. From project directory: streamlit run app.py
3. Open browser at: http://localhost:8501
4. Enter question
5. Adjust Top-K slider if needed
6. Click Search

Expected Output:
  * Clean UI
  * Grounded answer
  * Source citations
  * Indexed chunk confirmation

ğŸ” Model & Parameter Choices
# Embedding Model: text-embedding-3-small
  * Cost-efficient
  * High semantic accuracy
  * Suitable for document search

# Chat Model: gpt-4o-mini
  * Fast
  * Affordable
  * Reliable for structured responses
  
# Chunking Strategy
   CHUNK_TOKENS = 700
   CHUNK_OVERLAP = 120
   TOP_K = 5
  Reasoning:
  * 700 tokens balances context richness and performance
  * 120 overlap prevents context loss
  * Top-K = 5 ensures answer quality without noise

ğŸ” Data Privacy
  * Policy PDFs remain local
  * Only embeddings and prompts are sent to OpenAI
  * ChromaDB runs locally
  * No external database is used

ğŸ“Š Key Features

âœ” Retrieval-Augmented Generation
âœ” Source citations
âœ” Local vector storage
âœ” Cost-efficient LLM usage
âœ” Interactive UI
âœ” Modular architecture

ğŸ‘¨â€ğŸ’» Author

Mohammad Sharif Islam
Advanced Certification in Generative AI (Batch 1)
ğŸ“§ sharifislam.workmail@gmail.com
ğŸ“ 9886431461
ğŸ”— LinkedIn: https://www.linkedin.com/in/mohammad-sharif-islam-b6218714/ 




    




