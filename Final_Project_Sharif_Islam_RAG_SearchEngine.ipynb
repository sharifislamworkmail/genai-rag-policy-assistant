{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95726345-1e91-4c39-9fd8-aa7b268bb564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai>=1.0.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from -r requirements.txt (line 1)) (2.21.0)\n",
      "Requirement already satisfied: chromadb>=0.4.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from -r requirements.txt (line 2)) (1.5.0)\n",
      "Requirement already satisfied: pypdf>=3.0.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from -r requirements.txt (line 3)) (6.7.1)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from -r requirements.txt (line 4)) (1.2.1)\n",
      "Requirement already satisfied: tiktoken>=0.5.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from -r requirements.txt (line 5)) (0.12.0)\n",
      "Requirement already satisfied: streamlit>=1.30.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from -r requirements.txt (line 6)) (1.54.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (0.13.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (2.12.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from openai>=1.0.0->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->-r requirements.txt (line 1)) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->-r requirements.txt (line 1)) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->-r requirements.txt (line 1)) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->-r requirements.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (1.4.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 2)) (0.40.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (2.2.6)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (1.24.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (1.39.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (0.22.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (0.51.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (0.23.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (35.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (9.1.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (3.11.7)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from chromadb>=0.4.0->-r requirements.txt (line 2)) (4.23.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from tiktoken>=0.5.0->-r requirements.txt (line 5)) (2025.9.1)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from streamlit>=1.30.0->-r requirements.txt (line 6)) (6.0.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from streamlit>=1.30.0->-r requirements.txt (line 6)) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=5.5 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from streamlit>=1.30.0->-r requirements.txt (line 6)) (6.2.6)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from streamlit>=1.30.0->-r requirements.txt (line 6)) (8.2.1)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from streamlit>=1.30.0->-r requirements.txt (line 6)) (3.1.46)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from streamlit>=1.30.0->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from streamlit>=1.30.0->-r requirements.txt (line 6)) (2.2.3)\n",
      "Requirement already satisfied: pillow<13,>=7.1.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from streamlit>=1.30.0->-r requirements.txt (line 6)) (11.2.1)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from streamlit>=1.30.0->-r requirements.txt (line 6)) (0.9.1)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from streamlit>=1.30.0->-r requirements.txt (line 6)) (6.32.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from streamlit>=1.30.0->-r requirements.txt (line 6)) (23.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from streamlit>=1.30.0->-r requirements.txt (line 6)) (0.10.2)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from streamlit>=1.30.0->-r requirements.txt (line 6)) (6.4.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from streamlit>=1.30.0->-r requirements.txt (line 6)) (6.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit>=1.30.0->-r requirements.txt (line 6)) (3.1.6)\n",
      "Requirement already satisfied: narwhals>=1.27.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit>=1.30.0->-r requirements.txt (line 6)) (2.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from click<9,>=7.0->streamlit>=1.30.0->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.30.0->-r requirements.txt (line 6)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.30.0->-r requirements.txt (line 6)) (5.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit>=1.30.0->-r requirements.txt (line 6)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit>=1.30.0->-r requirements.txt (line 6)) (2025.2)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from build>=1.0.3->chromadb>=0.4.0->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit>=1.30.0->-r requirements.txt (line 6)) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (0.22.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (0.10)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=0.4.0->-r requirements.txt (line 2)) (25.2.10)\n",
      "Requirement already satisfied: sympy in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=0.4.0->-r requirements.txt (line 2)) (1.13.3)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (0.60b1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from rich>=10.11.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from rich>=10.11.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from tokenizers>=0.13.2->chromadb>=0.4.0->-r requirements.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.0->-r requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.0->-r requirements.txt (line 2)) (2024.6.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.0->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.0->-r requirements.txt (line 2)) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.0->-r requirements.txt (line 2)) (0.23.1)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from typer>=0.9.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (0.0.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 2)) (0.7.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 2)) (16.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 2)) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lenovo\\anaconda3\\envs\\env_genai\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.4.0->-r requirements.txt (line 2)) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CELL 1 — Install packages\n",
    "# =========================\n",
    "# Purpose:\n",
    "# - Installs all required libraries for:\n",
    "#   1) Loading PDFs\n",
    "#   2) Chunking text into token-sized pieces\n",
    "#   3) Creating embeddings via OpenAI\n",
    "#   4) Storing/searching embeddings in ChromaDB\n",
    "# Run:\n",
    "# - Only once per new environment (or when examiner runs on a fresh machine)\n",
    "\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# openai – Used to generate embeddings and produce final LLM answers from the OpenAI models.\n",
    "# chromadb – Used as the local vector database to store and retrieve embedded document chunks.\n",
    "# pypdf – Used to read and extract text from policy PDF files.\n",
    "# python-dotenv – Used to securely load the OpenAI API key from a .env file.\n",
    "# tiktoken – Used to split text into token-based chunks for better embedding and retrieval accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a0fab95-69f1-461d-8ab8-771360d5f0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY loaded ✅ sk-proj...\n",
      "OpenAI client initialized ✅\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 2 — Load API key (.env) + OpenAI client\n",
    "# ==========================================\n",
    "# Purpose:\n",
    "# - Loads OPENAI_API_KEY from a local .env file (so that we do not hardcode in our code).\n",
    "# - Creates the OpenAI client object used later for embeddings + answers.\n",
    "# Notes for examiner:\n",
    "# - To run this notebook end-to-end on examiners machine, the examiner needs their own OPENAI_API_KEY\n",
    "#   with API billing enabled.\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Loads .env from the current working directory (same folder where we have this notebook)\n",
    "load_dotenv(override=True)\n",
    "\n",
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not key:\n",
    "    raise RuntimeError(\n",
    "        \"OPENAI_API_KEY not found. Create a .env file in the SAME folder as this notebook with:\\n\"\n",
    "        \"OPENAI_API_KEY=sk-...\\n\"\n",
    "        \"Do not share your API key publicly.\"\n",
    "    )\n",
    "\n",
    "client = OpenAI()\n",
    "print(\"OPENAI_API_KEY loaded ✅\", key[:7] + \"...\")\n",
    "print(\"OpenAI client initialized ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5d267f7-014a-4dca-a44a-c4ef4006e843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: D:\\Gen_AI\\Final Project\\Policy documents\n",
      "CHROMA_DIR: D:\\Gen_AI\\Final Project\\chroma_db\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 3 — Configuration (paths + model choices)\n",
    "# ==========================================\n",
    "# Purpose:\n",
    "# - Sets:\n",
    "#   1) Where the PDFs are located (relative path)\n",
    "#   2) Where ChromaDB should store its persistent index (relative path)\n",
    "#   3) Which OpenAI models to use\n",
    "#   4) Chunking and retrieval parameters\n",
    "# Portability:\n",
    "# - Use relative paths so the examiner can run the project directly after downloading or cloning it.\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"./Policy documents\")   # put PDFs here\n",
    "CHROMA_DIR = Path(\"./chroma_db\")        # will be created on first index run\n",
    "\n",
    "# Models\n",
    "EMBED_MODEL = \"text-embedding-3-small\"\n",
    "CHAT_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "# RAG settings\n",
    "CHUNK_TOKENS = 700\n",
    "CHUNK_OVERLAP = 120\n",
    "TOP_K = 5\n",
    "\n",
    "COLLECTION_NAME = \"office_policy_rag\"\n",
    "\n",
    "print(\"DATA_DIR:\", DATA_DIR.resolve())\n",
    "print(\"CHROMA_DIR:\", CHROMA_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cb99133-1856-48b4-b5a7-1d37bdfd6222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total extracted pages: 11\n",
      "Example page: XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf page 1\n",
      "XYZ Dummy Company LTD - India Employee Policy Handbook (Fictitious)\n",
      "Page 1\n",
      " XYZ Dummy Company LTD\n",
      " India Employee Policy Handbook\n",
      "Version 1.0 | Effective date: 15 Feb 2026\n",
      "Disclaimer (for academic/demo use): This handbook is a fictitious sample created for a GenAI/RAG\n",
      "capstone. It is not legal advic\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 4 — Load PDFs (extract text page-by-page)\n",
    "# ==========================================\n",
    "# Purpose:\n",
    "# - Reads all PDFs under DATA_DIR (including subfolders).\n",
    "# - Extracts text from each page and stores metadata for citations.\n",
    "# Output:\n",
    "# - raw_pages: list of dicts with keys: text, source, path, page\n",
    "\n",
    "from pypdf import PdfReader\n",
    "\n",
    "def load_pdfs(folder: Path):\n",
    "    pages = []\n",
    "    pdf_files = list(folder.rglob(\"*.pdf\"))\n",
    "\n",
    "    if not pdf_files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No PDFs found in {folder}. Create the folder and add PDFs, e.g.\\n\"\n",
    "            f\"{folder}/policy1.pdf\"\n",
    "        )\n",
    "\n",
    "    for pdf_path in pdf_files:\n",
    "        reader = PdfReader(str(pdf_path))\n",
    "        for page_num, page in enumerate(reader.pages, start=1):\n",
    "            text = (page.extract_text() or \"\").strip()\n",
    "            if text:\n",
    "                pages.append({\n",
    "                    \"text\": text,\n",
    "                    \"source\": pdf_path.name,\n",
    "                    \"path\": str(pdf_path),\n",
    "                    \"page\": page_num\n",
    "                })\n",
    "    return pages\n",
    "\n",
    "raw_pages = load_pdfs(DATA_DIR)\n",
    "print(\"Total extracted pages:\", len(raw_pages))\n",
    "\n",
    "# Preview one page to confirm extraction looks correct\n",
    "print(\"Example page:\", raw_pages[0][\"source\"], \"page\", raw_pages[0][\"page\"])\n",
    "print(raw_pages[0][\"text\"][:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b95482cf-bc03-47ce-8c3b-470efe1cc8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 11\n",
      "Example chunk_id: XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p1:c0\n",
      "XYZ Dummy Company LTD - India Employee Policy Handbook (Fictitious)\n",
      "Page 1\n",
      " XYZ Dummy Company LTD\n",
      " India Employee Policy Handbook\n",
      "Version 1.0 | Effective date: 15 Feb 2026\n",
      "Disclaimer (for academic/demo use): This handbook is a fictitious sample created for a GenAI/RAG\n",
      "capstone. It is not legal advic\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 5 — Chunk pages into token-sized chunks\n",
    "# ==========================================\n",
    "# Purpose:\n",
    "# - Splits long page text into overlapping chunks for better retrieval.\n",
    "# - Uses token-based chunking (more stable for LLM context than characters).\n",
    "# Output:\n",
    "# - chunks: list of dicts with keys: chunk, source, path, page, chunk_id\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def chunk_text(text: str, chunk_tokens: int, overlap: int):\n",
    "    tokens = enc.encode(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "\n",
    "    while start < len(tokens):\n",
    "        end = min(start + chunk_tokens, len(tokens))\n",
    "        chunk = enc.decode(tokens[start:end]).strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        start = end - overlap\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        if end == len(tokens):\n",
    "            break\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def make_chunks(pages):\n",
    "    out = []\n",
    "    for p in pages:\n",
    "        page_chunks = chunk_text(p[\"text\"], CHUNK_TOKENS, CHUNK_OVERLAP)\n",
    "        for i, ch in enumerate(page_chunks):\n",
    "            out.append({\n",
    "                \"chunk\": ch,\n",
    "                \"source\": p[\"source\"],\n",
    "                \"path\": p[\"path\"],\n",
    "                \"page\": p[\"page\"],\n",
    "                \"chunk_id\": f'{p[\"source\"]}:p{p[\"page\"]}:c{i}'\n",
    "            })\n",
    "    return out\n",
    "\n",
    "chunks = make_chunks(raw_pages)\n",
    "print(\"Total chunks created:\", len(chunks))\n",
    "print(\"Example chunk_id:\", chunks[0][\"chunk_id\"])\n",
    "print(chunks[0][\"chunk\"][:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "225e4eaa-acae-4401-be1d-bea8ed2aba16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection already indexed ✅ 11\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 6 — Create/load ChromaDB + index documents (with safety checks + optional rebuild)\n",
    "# ==========================================\n",
    "# Purpose:\n",
    "# - Creates/loads a persistent local vector DB (ChromaDB) in CHROMA_DIR.\n",
    "# - Uses OpenAI embeddings to embed your chunks and store them in a collection.\n",
    "# - Skips indexing if already indexed, unless you set REBUILD_INDEX = True.\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import EmbeddingFunction\n",
    "\n",
    "# ---- (A) Required objects check (gives clear errors)\n",
    "required = [\"CHROMA_DIR\", \"COLLECTION_NAME\", \"EMBED_MODEL\", \"chunks\", \"client\"]\n",
    "missing = [v for v in required if v not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(\n",
    "        f\"Missing required variables: {missing}\\n\"\n",
    "        \"Fix:\\n\"\n",
    "        \"- Run the earlier cells in order (especially the OpenAI client init cell that sets `client = OpenAI()`).\\n\"\n",
    "        \"- Ensure chunking cell ran and created `chunks`.\\n\"\n",
    "    )\n",
    "\n",
    "# ---- (B) Optional: force rebuild when you change PDFs\n",
    "# Set to True if you changed PDFs and want to re-index from scratch.\n",
    "REBUILD_INDEX = False  # <-- change to True when documents change\n",
    "\n",
    "class OpenAIEmbedder(EmbeddingFunction):\n",
    "    def __init__(self, client, model, batch_size=64):\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __call__(self, texts):\n",
    "        embeddings = []\n",
    "        for i in range(0, len(texts), self.batch_size):\n",
    "            batch = texts[i:i+self.batch_size]\n",
    "            resp = self.client.embeddings.create(model=self.model, input=batch)\n",
    "            embeddings.extend([item.embedding for item in resp.data])\n",
    "        return embeddings\n",
    "\n",
    "# Persistent Chroma DB on disk\n",
    "chroma_client = chromadb.PersistentClient(path=str(CHROMA_DIR))\n",
    "embedder = OpenAIEmbedder(client, EMBED_MODEL, batch_size=64)\n",
    "\n",
    "# If documents changed, wipe the old collection so we don't mix old + new content\n",
    "if REBUILD_INDEX:\n",
    "    try:\n",
    "        chroma_client.delete_collection(name=COLLECTION_NAME)\n",
    "        print(\"Old collection deleted ✅ (rebuild requested)\")\n",
    "    except Exception:\n",
    "        print(\"No existing collection to delete (continuing)\")\n",
    "\n",
    "# Create/get collection\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    embedding_function=embedder\n",
    ")\n",
    "\n",
    "# Index chunks only if empty\n",
    "if collection.count() == 0:\n",
    "    ids = [c[\"chunk_id\"] for c in chunks]\n",
    "    documents = [c[\"chunk\"] for c in chunks]\n",
    "    metadatas = [{\"source\": c[\"source\"], \"path\": c[\"path\"], \"page\": c[\"page\"]} for c in chunks]\n",
    "\n",
    "    BATCH = 256\n",
    "    for i in range(0, len(ids), BATCH):\n",
    "        collection.add(\n",
    "            ids=ids[i:i+BATCH],\n",
    "            documents=documents[i:i+BATCH],\n",
    "            metadatas=metadatas[i:i+BATCH]\n",
    "        )\n",
    "\n",
    "    print(\"Indexed chunks ✅\", collection.count())\n",
    "else:\n",
    "    print(\"Collection already indexed ✅\", collection.count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bac0e3a-328c-4fd5-a0e1-1080e2103cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 7 — Retrieval (vector search)\n",
    "# ==========================================\n",
    "# Purpose:\n",
    "# - Given a user query, retrieves TOP_K most relevant chunks from ChromaDB.\n",
    "# Output:\n",
    "# - List of hits with chunk text + metadata for citations.\n",
    "\n",
    "def retrieve(query: str, top_k: int = TOP_K):\n",
    "    res = collection.query(query_texts=[query], n_results=top_k)\n",
    "    hits = []\n",
    "    for doc, meta, _id in zip(res[\"documents\"][0], res[\"metadatas\"][0], res[\"ids\"][0]):\n",
    "        hits.append({\"id\": _id, \"text\": doc, \"meta\": meta})\n",
    "    return hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d731eddb-bd2b-4099-ab91-cbb4c9ff11dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 8 — Answer generation (RAG: retrieve then generate)\n",
    "# ==========================================\n",
    "# Purpose:\n",
    "# - Uses retrieved chunks as grounded context.\n",
    "# - Forces the model to answer ONLY from provided excerpts.\n",
    "# - If not found, the model should say it couldn't find it.\n",
    "# Output:\n",
    "# - final answer text + the retrieved hits for transparency.\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a policy assistant for India-based employees.\n",
    "Answer ONLY using the provided policy excerpts.\n",
    "If the answer is not in the excerpts, say: \"I couldn't find this in the provided policies.\"\n",
    "Keep the answer concise and practical.\n",
    "Always end with citations in this format: (Source, page).\"\"\"\n",
    "\n",
    "def answer(query: str, top_k: int = TOP_K):\n",
    "    hits = retrieve(query, top_k=top_k)\n",
    "\n",
    "    context = \"\\n\\n\".join(\n",
    "        [f\"[{h['id']}] ({h['meta']['source']}, page {h['meta']['page']})\\n{h['text']}\"\n",
    "         for h in hits]\n",
    "    )\n",
    "\n",
    "    user_input = f\"Question: {query}\\n\\nPolicy excerpts:\\n{context}\"\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model=CHAT_MODEL,\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return resp.output_text, hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36116043-3391-429f-8efb-2a714b848901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Mention Policy name that you want to know about? (or 'exit'):  dress\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANSWER:\n",
      " The dress code at XYZ Dummy Company LTD supports a professional workplace and is business casual by default. However, stricter attire may be required at client sites. Employees should avoid clothing with offensive text or images, and safety gear must be used in designated areas (Source, page 3).\n",
      "\n",
      "TOP SOURCES USED:\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 3 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p3:c0\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 11 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p11:c0\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 2 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p2:c0\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 6 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p6:c0\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 1 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p1:c0\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Mention Policy name that you want to know about? (or 'exit'):  leave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANSWER:\n",
      " Employees are entitled to various types of leave, including annual/earned leave and sick leave, depending on employment type and location. Requests for leave should be submitted in the HR system in advance where possible, and medical documentation may be required for extended sick leave. It's important for employees to inform their manager/HR as early as possible and provide required documentation to avoid unexplained absences, which may lead to disciplinary actions (Source, page 6).\n",
      "\n",
      "TOP SOURCES USED:\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 6 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p6:c0\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 5 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p5:c0\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 10 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p10:c0\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 8 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p8:c0\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 9 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p9:c0\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Mention Policy name that you want to know about? (or 'exit'):  food\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANSWER:\n",
      " I couldn't find this in the provided policies.\n",
      "\n",
      "TOP SOURCES USED:\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 11 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p11:c0\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 9 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p9:c0\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 3 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p3:c0\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 6 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p6:c0\n",
      "- XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf | page 4 | XYZ_Dummy_Company_LTD_India_Employee_Policies.pdf:p4:c0\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Mention Policy name that you want to know about? (or 'exit'):  exit\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CELL 9 — Interactive demo (multiple questions)\n",
    "# ==========================================\n",
    "# Purpose:\n",
    "# - Lets the user/examiner ask multiple questions without editing the code each time.\n",
    "# - Each question is sent to the RAG pipeline:\n",
    "#   1) retrieve() pulls the most relevant TOP_K chunks from ChromaDB\n",
    "#   2) answer() sends those chunks + the question to the LLM to generate a grounded response\n",
    "# - Prints the final answer plus the supporting sources (PDF name + page) for verification.\n",
    "# How to use:\n",
    "# - Type a question and press Enter.\n",
    "# - Type 'exit' to stop the demo loop.\n",
    "\n",
    "while True:\n",
    "    query = input(\"Mention Policy name that you want to know about? (or 'exit'): \").strip()\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    final_answer, hits = answer(query)\n",
    "\n",
    "    print(\"\\nANSWER:\\n\", final_answer)\n",
    "    print(\"\\nTOP SOURCES USED:\")\n",
    "    for h in hits:\n",
    "        print(\"-\", h[\"meta\"][\"source\"], \"| page\", h[\"meta\"][\"page\"], \"|\", h[\"id\"])\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4fff3-b614-42bc-9f70-e3d183699a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
